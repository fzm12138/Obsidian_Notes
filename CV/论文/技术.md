输入--->卷积--->池化--->卷积--->池化--->...--->全连接-->输出
多层卷积池化非线性变换提取出多个特征层
每个特征层都可以认为是对输入图像的某种不同抽象程度的表示，网络的不断深入，特征的抽象程度逐渐增加
- 输出层对图像进行分类或回归预测
- 输出层对图像进行分类或回归预测
- 卷积输入为二维或三维的张量，通常转为二维矩阵作为输入

- 在卷积神经网络中，输入的图像经过多层卷积和池化操作后，可以得到高层次的特征表示。这些特征表示被送入全连接层，最终输出网络的预测结果。整个过程是一个端到端的过程，通过反向传播算法进行自动优化。在反向传播过程中，首先计算输出结果与真实标签之间的误差。然后，误差被反向传播回网络中的每个神经元，以计算每个神经元对误差的贡献。根据这些贡献更新网络中的参数，使得误差逐渐减小。通过不断地反复训练和更新，卷积神经网络可以学习到输入图像中的特征，并能够将其正确地分类
#### 步骤1：数据预处理：
- 对输入图像进行与处理
- 缩放、归一化、数据增强、去噪等
#### 步骤2：网络设计：
- 设计神经网络结构
- 考虑每个组件的参数和超参数的选择
- 确保网络的有效性和性能
#### 步骤3：损失函数定义
- 通过损失函数衡量模型预测结果与真实标签的差异
- 根据情况选择适合的损失函数可以帮助模型快速收敛
#### 步骤4：模型训练
- 通过优化算法更新模型参数
- 根据模型在训练数据上的表现，计算损失函数并反向传播误差，更新模型的参数以最小化损失函数
- 这样就可以学习到数据中的规律和模式，提高新数据的泛化能力
#### 步骤5：模型评估
- 通过对模型在验证集上的表现进行分析，判断模型的优化方向和确定参数调整的策略
#### 步骤6：模型调优
- 调整模型超参数，提高模型性能
- 判断模型优化方向和确定参数调整策略
#### 步骤7：模型测试
- 训练完成后，用测试集对模型进行测试评估
## 卷积神经网络基本结构
### 输入层
- 输入层接收的图像数据通常是三维矩阵
	- ***高度、宽度、通道数***
- 为了使输入数据的尺寸一致，需要预处理
- 尺寸裁剪、像素值归一化[0,1]
### 卷积层
- 在输入数据的不同区域上应用一个卷积核
- 将每个区域计算结果相加，所得数据就是卷积核在该位置提取的特征值
- 卷积核大小通常由具有nk×nk维度的方阵
	- nk是整数,通常是3或5这样的数值
- 该参数决定了每次卷积操作中覆盖的区域大小
- 卷积层中包含偏置值，用于对卷积核提取的特征进行偏移调整
- 卷积核大小要小于信号大小，因为卷积核必须在输入信号上滑动才能计算输入值
- 滑动时边缘处无法覆盖卷积核，会出现边缘效应
	- 在输入信号边缘填充像素值使得卷积核完全覆盖输入信号
	- 填充的像素值通常为0，也可以其他值
### 池化层
- 理论上卷积层输出的特征图可以直接使用
- 直接训练增训练负担，容易过拟合
- 常常用不同位置的特征进行聚合统计（池化）
- 池化层可以在提取特征的过程中逐渐降低特征图的维度
	- 池化层有助于防止过拟合
- 一般池化是在每个特征图上划分一定大小的池化窗口，每个池化窗口内取一个汇聚值
- 最常见的池化方法是
	- ***平均池化***
		- 取池化窗口内所有元素的平均值作为汇聚值
	- ***最大池化***
		- 每个池化窗口内取一个最大值作为该窗口汇聚值
	- 最大池化强调特征图中最重要的信息
	- 平均池化更平衡各个部分的信息
	- 池化操作的大小和步长可以自由设置，保持特征图的大小不变或缩小
### 全连接层
- 密集层，线性层层
- 建立输入数据和输出数据之间映射的关键
- 多个全连接层互相堆叠构成深层次网络结构
- 可以将高维输入数据映射到低维输出数据，实现压缩和将为
### 激活函数
用于神经网络中共的非线性变换函数，将输入信号进行非线性变换使得模型可以你和更复杂的函数关系，输出新特征
- sigmoid函数：
	- 输出值在0到1之间，二分类问题，容易梯度消失
		- ***不适合深层网络***
- Tanh函数：
	-  输出值在-1到1之间。比sigmoid函数具有更强的非线性特性，同样容易出现梯度消失问题
	- ***不适合深层网络***
- ReLu函数
	- 输出值在0到正无穷之间，简单，易于计算，深层网络优秀
	- 负数区间导数为0，会导致神经元死亡，影响模型表现
- Leaky ReLU是神经网络中ReLU函数的变体
	- 负值有小斜率，f(x)=max(αx,x)
		- x为正数，Leaky ReLU类似ReLu
		- x为负数，小斜率α
- 激活函数可以插入在各种层之后，对性能影响很重要
### Softmax分类层
- 多类别分类器，将输入向量分配到多个类别中的一个
- 给定的输入向量x和对应的权重矩阵W，计算得到加权和z
	- z=W<sup>t</sup>x
	- W每一列对应一个类别，然后将z传入Softmax函数
	- 产生每个类别的概率分布
	- `论文p15开头部分`
### 图像分类
将一张给定的图片分到不同类别中，卷积神经网络的图像分类流程是端到端的过程，原始输入到最终输出的所有操作都是神经网络完成，无需手动提取特征
![[卷积神经网络图像分类流程图.png]]


- 应用中图像要进行细粒度分类，将同一组属于同一打雷的图片分成不同类别
- 更加关注图像的细节和局部特征
- 细粒度方法分为
	- 局部特征
	- 基于部件
	- 基于深度学习
	- 基于度量学习
	- 基于关系推理
- ***基于局部特征：***
	- 检测和识别图像中局部特征分辨不同的子类别
	- SIFT HOG LBP等算法提取局部特征
	- SVM 决策树等分类器进行分类
		- **对图像中的一些局部变化可以进行很好的适应，比如颜色、形状、纹理**
		- **对物体的全局特征无考虑，易受 光照遮挡等的影响**
- ***基于部件：***
	- 检测和识别物体的部件进行分类
	- 对于害虫，分类头、翅膀、腿等
	- 根据部件的组合分类
		- **可以克服干扰问题**
		- **需要对图像进行分割和检测，需要确定部件的组合方式**
- ***基于深度学习：***
	- 卷积神经网络等，提取特征分类
	- 比如使用Inception、ResNet等深度学习模型进行细粒度图像分类
		- **自动学习图像特征，可以对全局和局部特征综合考虑**
		- **需要大量训练、大量计算资源**
- ***基于度量学习：***
	- 通过学习图像相似度进行分类
	- 孪生网络学习图像间相似度，根据相似度对图像进行分类
		- **需要大量样本和计算资源，对噪声和变化敏感**
- ***基于关系推理：***
	- 利用图像中物体之间的关系
		- 使用图神经网络学习图像中不同物体之间的关系，根据瓜西分类
		- 可以考虑不同物体之间的关系，区分不同的子类别
		- **大量训练样本、计算资源、对物体的位置和数量敏感**
#### ResNet18网络模型
- 残差学习，












